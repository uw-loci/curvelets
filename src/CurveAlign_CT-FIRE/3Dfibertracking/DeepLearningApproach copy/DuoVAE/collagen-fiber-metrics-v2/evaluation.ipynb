{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from centerline import CenterLine, smooth_mask, iou\n",
    "from scipy import io as sio\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage import io, morphology, img_as_float, filters, exposure\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing set 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cfcaa997f44eb09d709963e28daee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Process a batch of network output\n",
    "# raw_input_fnames = glob('evaluations/pilot/aug_output/resTe/*_I.png') # raw input\n",
    "nw_fnames = glob('evaluations/pilot/41nw_output/processed/skeletonize/0/*.tif') # nw masks\n",
    "aug_fnames = glob('evaluations/pilot/50_output/processed/skeletonize/0/*.tif') # aug masks\n",
    "target_fnames = glob('evaluations/pilot/target/0/*_Ltrue.png') # truth masks\n",
    "mat_fnames = glob('evaluations/pilot/ctFIRE_out/0/*.tif') # ctFIRE masks\n",
    "ridge_fnames = glob('evaluations/pilot/ridge_detector/0/*.tif') # ctFIRE masks\n",
    "\n",
    "ridge_feats = []\n",
    "mat_feats = []\n",
    "nw_feats = []\n",
    "aug_feats = []\n",
    "truth_feats = []\n",
    "\n",
    "### generate from output masks\n",
    "for i in tqdm(range(len(nw_fnames))):\n",
    "    nw_fname = nw_fnames[i]\n",
    "    aug_fname = aug_fnames[i]\n",
    "    target_fname = target_fnames[i]\n",
    "    mat_fname = mat_fnames[i]\n",
    "    ridge_fname = ridge_fnames[i]\n",
    "\n",
    "    ### ground truth\n",
    "    centerline = CenterLine(centerline_image=io.imread(target_fname))\n",
    "    centerline.compute_fiber_feats() \n",
    "    truth_feats.append(centerline.feats)\n",
    "\n",
    "    ## nw\n",
    "    centerline_nw = CenterLine(centerline_image=io.imread(nw_fname))\n",
    "    centerline_nw.compute_fiber_feats() \n",
    "    nw_feats.append(centerline_nw.feats)\n",
    "\n",
    "    ### aug\n",
    "    centerline_aug = CenterLine(centerline_image=io.imread(aug_fname))\n",
    "    centerline_aug.compute_fiber_feats() \n",
    "    aug_feats.append(centerline_aug.feats)\n",
    "\n",
    "    ### ridge detector\n",
    "    centerline_ridge = CenterLine(centerline_image=io.imread(ridge_fname))\n",
    "    centerline_ridge.compute_fiber_feats() \n",
    "    ridge_feats.append(centerline_ridge.feats)\n",
    "\n",
    "    ### ctFIRE\n",
    "    centerline_mat = CenterLine(centerline_image=io.imread(mat_fname))\n",
    "    centerline_mat.compute_fiber_feats() \n",
    "    mat_feats.append(centerline_mat.feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'evaluations/ridge_feats_0.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### read saved results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mevaluations/ridge_feats_0.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     ridge_feats \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluations/mat_feats_0.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/LOCI/DuoVAE/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'evaluations/ridge_feats_0.pkl'"
     ]
    }
   ],
   "source": [
    "### read saved results\n",
    "with open('evaluations/ridge_feats_0.pkl', 'rb') as f:\n",
    "    ridge_feats = pickle.load(f)\n",
    "    \n",
    "with open('evaluations/mat_feats_0.pkl', 'rb') as f:\n",
    "    mat_feats = pickle.load(f)\n",
    "\n",
    "with open('evaluations/nw_feats_0.pkl', 'rb') as f:\n",
    "    nw_feats = pickle.load(f)\n",
    "\n",
    "with open('evaluations/truth_feats_0.pkl', 'rb') as f:\n",
    "    truth_feats = pickle.load(f)\n",
    "\n",
    "with open('evaluations/aug_feats_0.pkl', 'rb') as f:\n",
    "    aug_feats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Process one kind of output\n",
    "# raw_input_fnames = glob('evaluations/pilot/aug_output/resTe/*_I.png') # raw input\n",
    "# sk_fnames = glob('evaluations/pilot/network_output/processed/skeletonize/*.tif') # nw masks\n",
    "\n",
    "# sk_feats = []\n",
    "\n",
    "# ### generate from output masks\n",
    "# for i in tqdm(range(len(raw_input_fnames))):\n",
    "#     sk_fname = sk_fnames[i]\n",
    "\n",
    "#     ### ground truth\n",
    "#     centerline = CenterLine(centerline_image=io.imread(sk_fname))\n",
    "#     centerline.compute_fiber_feats() \n",
    "#     sk_feats.append(centerline.feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_type = {}\n",
    "for feat in truth_feats:\n",
    "    for k, v in feat.items():\n",
    "        try:\n",
    "            feat_type[k].append(v)\n",
    "        except:\n",
    "            feat_type[k] = [v]\n",
    "\n",
    "feat_bound = {}\n",
    "for k, v in feat_type.items():\n",
    "    feat_bound[k] = (np.percentile(v, 0), np.percentile(v, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats_diff(feats_in, feats_ref, bound=None, abs_val=True):\n",
    "    diff = []\n",
    "    cir_dist = lambda x, y, r=math.pi: min(r - abs(x - y), abs(x - y))\n",
    "    normalize = lambda x, k, bound : exposure.rescale_intensity(np.array([x]), in_range=(bound[k][0], bound[k][1]), out_range=(0, 1))[0]\n",
    "    for k, v in feats_in.items():\n",
    "        if bound:\n",
    "            feat_in = normalize(feats_in[k], k, bound) \n",
    "            feat_ref = normalize(feats_ref[k], k, bound)\n",
    "        else:\n",
    "            feat_in = feats_in[k]\n",
    "            feat_ref = feats_ref[k]\n",
    "        if k == 'cir_mean':\n",
    "            diff.append(cir_dist(feats_in[k], feats_ref[k]))\n",
    "        elif k == 'density':\n",
    "            ratio, U, I = iou(feat_in, feat_ref)\n",
    "            diff.append(ratio)\n",
    "        else:\n",
    "            if abs_val: \n",
    "                diff.append(abs(feat_in - feat_ref))\n",
    "            else: \n",
    "                diff.append(feat_in - feat_ref)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge normalized error : cir_mean 0.0584 cir_var 0.1649 len_mean 0.0955 len_var 0.0877 waviness 0.2997 intensity 0.1604 || IoU: 0.6704\n",
      "ctFIRE normalized error : cir_mean 0.0597 cir_var 0.1172 len_mean 0.0718 len_var 0.1033 waviness 0.2278 intensity 0.0945 || IoU: 0.6778\n",
      "Network normalized error : cir_mean 0.0567 cir_var 0.0728 len_mean 0.0555 len_var 0.0712 waviness 0.1288 intensity 0.0628 || IoU: 0.7414\n",
      "Aug normalized error : cir_mean 0.0527 cir_var 0.0781 len_mean 0.0541 len_var 0.0617 waviness 0.1412 intensity 0.0588 || IoU: 0.7437\n"
     ]
    }
   ],
   "source": [
    "ridge_diffs = []\n",
    "mat_diffs = []\n",
    "nw_diffs = []\n",
    "aug_diffs = []\n",
    "for i in range(len(ridge_feats)):\n",
    "    ridge_diffs.append(feats_diff(ridge_feats[i], truth_feats[i]))\n",
    "    mat_diffs.append(feats_diff(mat_feats[i], truth_feats[i]))\n",
    "    nw_diffs.append(feats_diff(nw_feats[i], truth_feats[i]))\n",
    "    aug_diffs.append(feats_diff(aug_feats[i], truth_feats[i]))\n",
    "ridge_diffs = np.stack(ridge_diffs)\n",
    "mat_diffs = np.stack(mat_diffs)\n",
    "nw_diffs = np.stack(nw_diffs)\n",
    "aug_diffs = np.stack(aug_diffs)\n",
    "\n",
    "max_diff = (math.pi, \n",
    "feat_bound['cir_var'][1]-feat_bound['cir_var'][0], \n",
    "feat_bound['len_mean'][1]-feat_bound['len_mean'][0], \n",
    "feat_bound['len_var'][1]-feat_bound['len_var'][0], \n",
    "feat_bound['waviness'][1]-feat_bound['waviness'][0], \n",
    "feat_bound['intensity'][1]-feat_bound['intensity'][0])\n",
    "\n",
    "normalize_error = lambda diff, max_diff: [diff[i]/max_diff[i] if i<6 else diff[i] for i in range(7)]\n",
    "norm_ridge_diffs = np.array([normalize_error(i, max_diff) for i in ridge_diffs])\n",
    "norm_mat_diffs = np.array([normalize_error(i, max_diff) for i in mat_diffs])\n",
    "norm_nw_diffs = np.array([normalize_error(i, max_diff) for i in nw_diffs])\n",
    "norm_aug_diffs = np.array([normalize_error(i, max_diff) for i in aug_diffs])\n",
    "\n",
    "summary = lambda name, diffs: print(f'{name} normalized error : cir_mean {diffs[0]:.4f} cir_var {diffs[1]:.4f} len_mean {diffs[2]:.4f} len_var {diffs[3]:.4f} waviness {diffs[4]:.4f} intensity {diffs[5]:.4f} || IoU: {diffs[6]:.4f}')\n",
    "summary('Ridge', np.mean(norm_ridge_diffs, 0))\n",
    "summary('ctFIRE',np.mean(norm_mat_diffs, 0))\n",
    "summary('Network',np.mean(norm_nw_diffs, 0))\n",
    "summary('Aug',np.mean(norm_aug_diffs, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge normalized error : cir_mean 0.0584 cir_var 0.1649 len_mean 0.0955 len_var 0.0877 waviness 0.2997 intensity 0.1604 || IoU: 0.6704  \n",
    "ctFIRE normalized error : cir_mean 0.0597 cir_var 0.1172 len_mean 0.0718 len_var 0.1033 waviness 0.2278 intensity 0.0945 || IoU: 0.6778  \n",
    "Network normalized error : cir_mean 0.0505 cir_var 0.0698 len_mean 0.0487 len_var 0.0694 waviness 0.1283 intensity 0.0647 || IoU: 0.7352  \n",
    "Aug normalized error : cir_mean 0.0481 cir_var 0.0737 len_mean 0.0510 len_var 0.0665 waviness 0.1281 intensity 0.0699 || IoU: 0.7391  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge normalized error : cir_mean 0.0579 cir_var 0.1652 len_mean 0.0750 len_var 0.0720 waviness 0.3269 intensity 0.1839 || IoU: 0.6585  \n",
    "ctFIRE normalized error : cir_mean 0.0624 cir_var 0.1274 len_mean 0.0680 len_var 0.1006 waviness 0.2498 intensity 0.1233 || IoU: 0.6561  \n",
    "Network normalized error : cir_mean 0.0508 cir_var 0.0871 len_mean 0.0391 len_var 0.0577 waviness 0.1540 intensity 0.0966 || IoU: 0.7086  \n",
    "\n",
    "Aug-v1 normalized error : cir_mean 0.0514 cir_var 0.0796 len_mean 0.0462 len_var 0.0680 waviness 0.1520 intensity 0.1163 || IoU: 0.7023 \n",
    "\n",
    "Aug-v2 normalized error : cir_mean 0.0503 cir_var 0.0905 len_mean 0.0450 len_var 0.0697 waviness 0.1573 intensity 0.1299 || IoU: 0.7026\n",
    "\n",
    "Aug-v3 normalized error : cir_mean 0.0515 cir_var 0.0845 len_mean 0.0517 len_var 0.0646 waviness 0.1442 intensity 0.1110 || IoU: 0.7000\n",
    "\n",
    "Aug-v4 normalized error : cir_mean 0.0511 cir_var 0.0814 len_mean 0.0461 len_var 0.0687 waviness 0.1476 intensity 0.1182 || IoU: 0.7041\n",
    "\n",
    "Aug-v4: normalized error : cir_mean 0.0457 cir_var 0.0730 len_mean 0.0461 len_var 0.0646 waviness 0.1437 intensity 0.1031 || IoU: 0.7042\n",
    "\n",
    "Aug-joon normalized error : cir_mean 0.0532 cir_var 0.0828 len_mean 0.0446 len_var 0.0693 waviness 0.1447 intensity 0.1520 || IoU: 0.6804\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('evaluations/ridge_feats_0.pkl', 'wb') as f:\n",
    "    pickle.dump(ridge_feats, f)\n",
    "        \n",
    "with open('evaluations/mat_feats_0.pkl', 'wb') as f:\n",
    "    pickle.dump(mat_feats, f)\n",
    "\n",
    "with open('evaluations/nw_feats_0.pkl', 'wb') as f:\n",
    "    pickle.dump(nw_feats, f)\n",
    "\n",
    "with open('evaluations/aug_feats_0.pkl', 'wb') as f:\n",
    "    pickle.dump(aug_feats, f)\n",
    "\n",
    "with open('evaluations/truth_feats_0.pkl', 'wb') as f:\n",
    "    pickle.dump(truth_feats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rank score: Ridge 2.0195 ctFIRE 1.7862 Network 1.1213 Aug 1.0730\n"
     ]
    }
   ],
   "source": [
    "diffs_pack = np.dstack([norm_ridge_diffs, norm_mat_diffs, norm_nw_diffs, norm_aug_diffs])\n",
    "pack = np.concatenate((diffs_pack[:, :6, :], (1-diffs_pack[:, -1, :])[:, None, :]), 1)\n",
    "sample_scores = []\n",
    "for i in range(pack.shape[0]):\n",
    "    stack = pack[i, :, :]\n",
    "    ranks =  np.argsort(stack, 1).argsort()\n",
    "    scores = np.mean(ranks, 0)\n",
    "    sample_scores.append(scores)\n",
    "sample_scores = np.vstack(sample_scores)\n",
    "rank_score = np.mean(sample_scores, 0)\n",
    "print(f'Average rank score: Ridge {rank_score[0]:.4f} ctFIRE {rank_score[1]:.4f} Network {rank_score[2]:.4f} Aug {rank_score[3]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4c31d3b24444a4b8495c72b4dafd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Process a batch of network output\n",
    "# raw_input_fnames = glob('evaluations/pilot/aug_output/resTe/*_I.png') # raw input\n",
    "nw_fnames = glob('evaluations/pilot/41nw_output/processed/skeletonize/1/*.tif') # nw masks\n",
    "aug_fnames = glob('evaluations/pilot/41aug_output/processed/skeletonize/1/*.tif') # aug masks\n",
    "target_fnames = glob('evaluations/pilot/target/1/*_Ltrue.png') # truth masks\n",
    "mat_fnames = glob('evaluations/pilot/ctFIRE_out/1/*.tif') # ctFIRE masks\n",
    "ridge_fnames = glob('evaluations/pilot/ridge_detector/1/*.tif') # ctFIRE masks\n",
    "\n",
    "ridge_feats = []\n",
    "mat_feats = []\n",
    "nw_feats = []\n",
    "aug_feats = []\n",
    "truth_feats = []\n",
    "\n",
    "### generate from output masks\n",
    "for i in tqdm(range(len(nw_fnames))):\n",
    "    nw_fname = nw_fnames[i]\n",
    "    aug_fname = aug_fnames[i]\n",
    "    target_fname = target_fnames[i]\n",
    "    mat_fname = mat_fnames[i]\n",
    "    ridge_fname = ridge_fnames[i]\n",
    "\n",
    "    ### ground truth\n",
    "    centerline = CenterLine(centerline_image=io.imread(target_fname))\n",
    "    centerline.compute_fiber_feats() \n",
    "    truth_feats.append(centerline.feats)\n",
    "\n",
    "    ### nw\n",
    "    centerline_nw = CenterLine(centerline_image=io.imread(nw_fname))\n",
    "    centerline_nw.compute_fiber_feats() \n",
    "    nw_feats.append(centerline_nw.feats)\n",
    "\n",
    "    ### aug\n",
    "    centerline_aug = CenterLine(centerline_image=io.imread(aug_fname))\n",
    "    centerline_aug.compute_fiber_feats() \n",
    "    aug_feats.append(centerline_aug.feats)\n",
    "\n",
    "    ### ridge detector\n",
    "    centerline_ridge = CenterLine(centerline_image=io.imread(ridge_fname))\n",
    "    centerline_ridge.compute_fiber_feats() \n",
    "    ridge_feats.append(centerline_ridge.feats)\n",
    "\n",
    "    ### ctFIRE\n",
    "    centerline_mat = CenterLine(centerline_image=io.imread(mat_fname))\n",
    "    centerline_mat.compute_fiber_feats() \n",
    "    mat_feats.append(centerline_mat.feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge normalized error : cir_mean 0.0579 cir_var 0.1652 len_mean 0.0750 len_var 0.0720 waviness 0.3269 intensity 0.1839 || IoU: 0.6585\n",
      "ctFIRE normalized error : cir_mean 0.0624 cir_var 0.1274 len_mean 0.0680 len_var 0.1006 waviness 0.2498 intensity 0.1233 || IoU: 0.6561\n",
      "Network normalized error : cir_mean 0.0518 cir_var 0.0767 len_mean 0.0445 len_var 0.0635 waviness 0.1407 intensity 0.0856 || IoU: 0.7127\n",
      "Aug normalized error : cir_mean 0.0471 cir_var 0.0835 len_mean 0.0438 len_var 0.0560 waviness 0.1510 intensity 0.0819 || IoU: 0.7151\n"
     ]
    }
   ],
   "source": [
    "ridge_diffs = []\n",
    "mat_diffs = []\n",
    "nw_diffs = []\n",
    "aug_diffs = []\n",
    "for i in range(len(ridge_feats)):\n",
    "    ridge_diffs.append(feats_diff(ridge_feats[i], truth_feats[i]))\n",
    "    mat_diffs.append(feats_diff(mat_feats[i], truth_feats[i]))\n",
    "    nw_diffs.append(feats_diff(nw_feats[i], truth_feats[i]))\n",
    "    aug_diffs.append(feats_diff(aug_feats[i], truth_feats[i]))\n",
    "ridge_diffs = np.stack(ridge_diffs)\n",
    "mat_diffs = np.stack(mat_diffs)\n",
    "nw_diffs = np.stack(nw_diffs)\n",
    "aug_diffs = np.stack(aug_diffs)\n",
    "\n",
    "feat_type = {}\n",
    "for feat in truth_feats:\n",
    "    for k, v in feat.items():\n",
    "        try:\n",
    "            feat_type[k].append(v)\n",
    "        except:\n",
    "            feat_type[k] = [v]\n",
    "\n",
    "feat_bound = {}\n",
    "for k, v in feat_type.items():\n",
    "    feat_bound[k] = (np.percentile(v, 0), np.percentile(v, 100))\n",
    "\n",
    "max_diff = (math.pi, \n",
    "feat_bound['cir_var'][1]-feat_bound['cir_var'][0], \n",
    "feat_bound['len_mean'][1]-feat_bound['len_mean'][0], \n",
    "feat_bound['len_var'][1]-feat_bound['len_var'][0], \n",
    "feat_bound['waviness'][1]-feat_bound['waviness'][0], \n",
    "feat_bound['intensity'][1]-feat_bound['intensity'][0])\n",
    "\n",
    "normalize_error = lambda diff, max_diff: [diff[i]/max_diff[i] if i<6 else diff[i] for i in range(7)]\n",
    "norm_ridge_diffs = np.array([normalize_error(i, max_diff) for i in ridge_diffs])\n",
    "norm_mat_diffs = np.array([normalize_error(i, max_diff) for i in mat_diffs])\n",
    "norm_nw_diffs = np.array([normalize_error(i, max_diff) for i in nw_diffs])\n",
    "norm_aug_diffs = np.array([normalize_error(i, max_diff) for i in aug_diffs])\n",
    "\n",
    "summary = lambda name, diffs: print(f'{name} normalized error : cir_mean {diffs[0]:.4f} cir_var {diffs[1]:.4f} len_mean {diffs[2]:.4f} len_var {diffs[3]:.4f} waviness {diffs[4]:.4f} intensity {diffs[5]:.4f} || IoU: {diffs[6]:.4f}')\n",
    "summary('Ridge', np.mean(norm_ridge_diffs, 0))\n",
    "summary('ctFIRE',np.mean(norm_mat_diffs, 0))\n",
    "summary('Network',np.mean(norm_nw_diffs, 0))\n",
    "summary('Aug',np.mean(norm_aug_diffs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rank score: Ridge 1.9663 ctFIRE 1.8600 Network 1.1034 Aug 1.0704\n"
     ]
    }
   ],
   "source": [
    "diffs_pack = np.dstack([norm_ridge_diffs, norm_mat_diffs, norm_nw_diffs, norm_aug_diffs])\n",
    "pack = np.concatenate((diffs_pack[:, :6, :], (1-diffs_pack[:, -1, :])[:, None, :]), 1)\n",
    "sample_scores = []\n",
    "for i in range(pack.shape[0]):\n",
    "    stack = pack[i, :, :]\n",
    "    ranks =  np.argsort(stack, 1).argsort()\n",
    "    scores = np.mean(ranks, 0)\n",
    "    sample_scores.append(scores)\n",
    "sample_scores = np.vstack(sample_scores)\n",
    "rank_score = np.mean(sample_scores, 0)\n",
    "print(f'Average rank score: Ridge {rank_score[0]:.4f} ctFIRE {rank_score[1]:.4f} Network {rank_score[2]:.4f} Aug {rank_score[3]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('evaluations/ridge_feats_1.pkl', 'wb') as f:\n",
    "    pickle.dump(ridge_feats, f)\n",
    "        \n",
    "with open('evaluations/mat_feats_1.pkl', 'wb') as f:\n",
    "    pickle.dump(mat_feats, f)\n",
    "\n",
    "with open('evaluations/nw_feats_1.pkl', 'wb') as f:\n",
    "    pickle.dump(nw_feats, f)\n",
    "\n",
    "with open('evaluations/aug_feats_1.pkl', 'wb') as f:\n",
    "    pickle.dump(aug_feats, f)\n",
    "\n",
    "with open('evaluations/truth_feats_1.pkl', 'wb') as f:\n",
    "    pickle.dump(truth_feats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('evaluations/ridge_diffs.pkl', 'wb') as f:\n",
    "    pickle.dump(norm_ridge_diffs, f)\n",
    "        \n",
    "with open('evaluations/mat_diffs.pkl', 'wb') as f:\n",
    "    pickle.dump(norm_mat_diffs, f)\n",
    "\n",
    "with open('evaluations/nw_diffs.pkl', 'wb') as f:\n",
    "    pickle.dump(norm_nw_diffs, f)\n",
    "\n",
    "with open('evaluations/aug_diffs.pkl', 'wb') as f:\n",
    "    pickle.dump(norm_aug_diffs, f)\n",
    "\n",
    "# with open('evaluations/truth_diffs.pkl', 'wb') as f:\n",
    "#     pickle.dump(truth_feats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read saved results\n",
    "with open('evaluations/ridge_feats_0.pkl', 'rb') as f:\n",
    "    ridge_feats = pickle.load(f)\n",
    "    \n",
    "with open('evaluations/mat_feats_0.pkl', 'rb') as f:\n",
    "    mat_feats = pickle.load(f)\n",
    "\n",
    "with open('evaluations/nw_feats_0.pkl', 'rb') as f:\n",
    "    nw_feats = pickle.load(f)\n",
    "\n",
    "with open('evaluations/truth_feats_0.pkl', 'rb') as f:\n",
    "    truth_feats = pickle.load(f)\n",
    "\n",
    "with open('evaluations/aug_feats_0.pkl', 'rb') as f:\n",
    "    aug_feats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge_feats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\experiments\\collagen-fiber-annotation\\evaluation.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/experiments/collagen-fiber-annotation/evaluation.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## read saved results\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/experiments/collagen-fiber-annotation/evaluation.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mevaluations/ridge_feats_1.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/experiments/collagen-fiber-annotation/evaluation.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     ridge_feats \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/experiments/collagen-fiber-annotation/evaluation.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mevaluations/mat_feats_1.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/experiments/collagen-fiber-annotation/evaluation.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     mat_feats \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ridge_feats' is not defined"
     ]
    }
   ],
   "source": [
    "## read saved results\n",
    "with open('evaluations/ridge_feats_1.pkl', 'rb') as f:\n",
    "    ridge_feats += pickle.load(f)\n",
    "    \n",
    "with open('evaluations/mat_feats_1.pkl', 'rb') as f:\n",
    "    mat_feats += pickle.load(f)\n",
    "\n",
    "with open('evaluations/nw_feats_1.pkl', 'rb') as f:\n",
    "    nw_feats += pickle.load(f)\n",
    "\n",
    "with open('evaluations/truth_feats_1.pkl', 'rb') as f:\n",
    "    truth_feats += pickle.load(f)\n",
    "\n",
    "with open('evaluations/aug_feats_1.pkl', 'rb') as f:\n",
    "    aug_feats += pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_list = []\n",
    "for item in aug_feats:\n",
    "    aug_list.append(list(item.values())[:-1])\n",
    "\n",
    "nw_list = []\n",
    "for item in nw_feats:\n",
    "    nw_list.append(list(item.values())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_arr = np.array(aug_list)\n",
    "nw_arr = np.array(nw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.193551229837585, pvalue=0.03222021342354551)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(aug_arr[:, 5], nw_arr[:, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b31907b65825698a9aebbc4c20fbd9f244fb3dbf0a5eee48a39fe40dfa032bc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
